{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "음식메뉴이미지검색기_주석추가.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCVKm1pGUffc"
      },
      "source": [
        "# 콜랩 사용 시 사용\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxb_ZCuXUs2J",
        "outputId": "f6aa768a-9284-45aa-b968-5be96e3e89ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-RaNXN5UlOT"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKolJm-RUffj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, utils\n",
        "from tensorflow.keras import models, layers, activations, initializers, losses, optimizers, metrics, regularizers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dut7BHiUffo"
      },
      "source": [
        "# 압축 풀 경로 설정(colab)\n",
        "# 음식이미지 폴더 생성 --> 압축 해제 후 저장 될 이미지 폴더\n",
        "# 음식이미지 zip 폴더 생성 --> zip 파일 저장될 폴더\n",
        "\n",
        "# zip 파일 // 음식 이미지 파일 구분해서 \n",
        "# 명령어로 파일 이동이 되지 않는 관계로 압축 해제 후 수동으로 옮길것!!!(필수)\n",
        "# 아래 주석으로 할 경우 체크포인트 발생으로 절대 쓰지 말 것!! 주석 풀린 것만 사용\n",
        "\n",
        "!mkdir 음식이미지\n",
        "!mkdir 음식이미지zip\n",
        "\n",
        "!unzip -uq 'drive/MyDrive/음식이미지.zip' -d '음식이미지/'\n",
        "\n",
        "\n",
        "\n",
        "# !mv 음식이미지_sample.zip 음식이미지/\n",
        "\n",
        "# !cd 음식이미지 && unzip 음식이미지_sample.zip\n",
        "# # !mv 음식이미지_sample.zip ./음식이미지zip/\n",
        "\n",
        "# !cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du6BIjvgUffr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lElbNayBUfft"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85gGfGmjUffv",
        "outputId": "63e5cff3-4aa4-4d4a-f756-16261de99ae7"
      },
      "source": [
        "# 음식이미지 내 폴더 명 확인 용도 (체크포인트 존재 유무 확인)\n",
        "\n",
        "!ls '음식이미지/NewNewNewNew'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "족발  보쌈\t   파김치  불고기    연근조림  감자조림    콩나물무침\n",
            "짬뽕  송편\t   미역국  김치찜    꽁치조림  곱창전골    계란후라이\n",
            "꿀떡  라면\t   호박죽  꼬막찜    콩나물국  동그랑땡    오징어튀김\n",
            "약과  육회\t   물냉면  깍두기    장어구이  열무국수    애호박볶음\n",
            "편육  물회\t   산낙지  수제비    가지볶음  시래기국    오이소박이\n",
            "수육  김밥\t   감자탕  무생채    나박김치  계란말이    김치볶음밥\n",
            "멍게  약식\t   주먹밥  콩국수    제육볶음  고추튀김    코다리조림\n",
            "쫄면  경단\t   추어탕  회무침    새우튀김  유부초밥    순두부찌개\n",
            "식혜  곰탕_설렁탕  생선전  계란국    닭볶음탕  배추김치    고등어조림\n",
            "파전  떡국_만두국  칼국수  전복죽    갈치조림  양념치킨    고사리나물\n",
            "잡채  육개장\t   갈비찜  닭계장    양념게장  숙주나물    시금치나물\n",
            "알밥  감자전\t   막국수  비빔밥    잔치국수  땅콩조림    꽈리고추무침\n",
            "무국  매운탕\t   떡꼬치  계란찜    동태찌개  김치찌개    미역줄기볶음\n",
            "순대  잡곡밥\t   떡갈비  해물찜    총각김치  더덕구이    후라이드치킨\n",
            "피자  콩자반\t   갓김치  장조림    우엉조림  황태구이    메추리알장조림\n",
            "한과  짜장면\t   과메기  백김치    비빔냉면  멸치볶음\n",
            "만두  김치전\t   호박전  두부김치  두부조림  도토리묵\n",
            "찜닭  수정과\t   삼계탕  간장게장  부추김치  깻잎장아찌\n",
            "젓갈  갈비탕\t   북엇국  된장찌개  홍어무침  도라지무침\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfwxocRbUffx",
        "outputId": "e065df96-f9f9-4e2f-b5b1-be98d6dd9e3c"
      },
      "source": [
        "# 메뉴명 리스트 생성\n",
        "\n",
        "path = '음식이미지/NewNewNewNew'\n",
        "\n",
        "menu = os.listdir(path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
        "\n",
        "\n",
        "len(menu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFUj2YVwUff1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0slHFMjBUff3",
        "outputId": "17272b59-0e9d-40bd-e0e0-fefed602e57e"
      },
      "source": [
        "# 메뉴 파일 내 이미지 파일 이름 생성\n",
        "\n",
        "menu_img_file_name = []\n",
        "\n",
        "for i in menu:\n",
        "    menu_img_file_name.append(os.listdir(path + '/' + i))\n",
        "\n",
        "len(menu_img_file_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osz9Kd6cUff9",
        "outputId": "8c9e1044-ccc0-4ede-ed35-5ba626393c0f"
      },
      "source": [
        "## file 불러오기 test\n",
        "## imread로 불러올 경우 경로 문제로 인하여 plt로 불러옴\n",
        "## 모델의 구성 효과가 잘 나오지 않을 경우 RGB 채널 변환 시도해봐야\n",
        "## data agmentation도 고려\n",
        "\n",
        "menu_img = []\n",
        "\n",
        "# for i in range(len(menu)):\n",
        "#     for j in range(len(menu_img_file_name[i])):\n",
        "#         file = path + '/' + menu[i] + '/' + menu_img_file_name[i][j]\n",
        "#         f = cv2.imread(file)\n",
        "#         menu_img.append(f)\n",
        "#         print(f)\n",
        "\n",
        "        \n",
        "file = path + '/' + menu[1] + '/' + menu_img_file_name[1][0]\n",
        "print(file)\n",
        "\n",
        "# img = cv2.imread(file)\n",
        "img = plt.imread(file)\n",
        "\n",
        "img\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "음식이미지/NewNewNewNew/육개장/Img_020_0069.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[160,  85,   4],\n",
              "        [160,  85,   2],\n",
              "        [162,  88,   3],\n",
              "        ...,\n",
              "        [ 98,  55,  23],\n",
              "        [ 93,  49,  20],\n",
              "        [ 94,  50,  21]],\n",
              "\n",
              "       [[160,  85,   2],\n",
              "        [160,  85,   2],\n",
              "        [161,  86,   3],\n",
              "        ...,\n",
              "        [ 96,  53,  21],\n",
              "        [ 97,  54,  22],\n",
              "        [ 94,  51,  19]],\n",
              "\n",
              "       [[161,  86,   3],\n",
              "        [161,  86,   3],\n",
              "        [161,  86,   3],\n",
              "        ...,\n",
              "        [ 97,  54,  20],\n",
              "        [102,  59,  27],\n",
              "        [ 98,  55,  23]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 54,  59,  52],\n",
              "        [ 56,  58,  53],\n",
              "        [ 57,  59,  54],\n",
              "        ...,\n",
              "        [ 95,  39,  22],\n",
              "        [ 95,  39,  22],\n",
              "        [ 94,  38,  21]],\n",
              "\n",
              "       [[ 58,  61,  54],\n",
              "        [ 53,  55,  50],\n",
              "        [ 52,  54,  49],\n",
              "        ...,\n",
              "        [ 94,  38,  21],\n",
              "        [ 95,  39,  22],\n",
              "        [ 94,  38,  23]],\n",
              "\n",
              "       [[ 53,  55,  50],\n",
              "        [ 52,  57,  51],\n",
              "        [ 56,  61,  55],\n",
              "        ...,\n",
              "        [ 95,  39,  24],\n",
              "        [ 95,  39,  24],\n",
              "        [ 94,  38,  23]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSdGABhaUff_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxIkDmX4UfgB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7-1DVaaUfgB"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3c8nM2LUfgD",
        "outputId": "c11f5037-6ed7-4d7c-dc1c-05b6a5b2cdbf"
      },
      "source": [
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        " \n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        path,  # This is the source directory for training images\n",
        "        target_size=(300, 300),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        class_mode='categorical')     # Categorical로"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11888 images belonging to 129 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG4Bit_IUfgE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U_fzUnOUfgE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3LATPGEUfgF"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
        "    \n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    \n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    \n",
        "    # \n",
        "    tf.keras.layers.Dense(129, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvPecdfjUfgG",
        "outputId": "501f61cd-9249-4fe9-aff2-8e88828ef60e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 129)               66177     \n",
            "=================================================================\n",
            "Total params: 1,769,761\n",
            "Trainable params: 1,769,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wLzuX_VUfgH"
      },
      "source": [
        "# from tensorflow.keras.optimizers import RMSprop\n",
        " \n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=RMSprop(lr=0.001),\n",
        "#               metrics=['acc'])\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              loss = keras.losses.CategoricalCrossentropy(),\n",
        "              metrics = ['accuracy']) # tf.keras.metrics.CategoricalAccuracy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QHeOVx6UfgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KXq_S0vUfgJ",
        "outputId": "77dcd466-e0b9-4c89-96b1-262cc1bcad67"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      batch_size=50,\n",
        "      steps_per_epoch=50,  \n",
        "      epochs=25,\n",
        "      verbose=1,\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "10/50 [=====>........................] - ETA: 7:02 - loss: 4.8619 - accuracy: 0.0063"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48/50 [===========================>..] - ETA: 20s - loss: 4.8065 - accuracy: 0.0131"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1078 bytes but only got 0. Skipping tag 37500\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 125 bytes but only got 120. Skipping tag 37510\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 527s 10s/step - loss: 4.7950 - accuracy: 0.0133\n",
            "Epoch 2/25\n",
            "50/50 [==============================] - 525s 10s/step - loss: 4.4579 - accuracy: 0.0328\n",
            "Epoch 3/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 37386\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37396\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 524s 10s/step - loss: 4.2400 - accuracy: 0.0650\n",
            "Epoch 4/25\n",
            "50/50 [==============================] - 527s 11s/step - loss: 3.9986 - accuracy: 0.0818\n",
            "Epoch 5/25\n",
            "50/50 [==============================] - 523s 10s/step - loss: 3.8018 - accuracy: 0.1126\n",
            "Epoch 6/25\n",
            "50/50 [==============================] - 526s 11s/step - loss: 3.5961 - accuracy: 0.1522\n",
            "Epoch 7/25\n",
            "50/50 [==============================] - 523s 10s/step - loss: 3.3938 - accuracy: 0.1823\n",
            "Epoch 8/25\n",
            "50/50 [==============================] - 524s 10s/step - loss: 3.2078 - accuracy: 0.2276\n",
            "Epoch 9/25\n",
            "50/50 [==============================] - 526s 10s/step - loss: 3.0010 - accuracy: 0.2624\n",
            "Epoch 10/25\n",
            "50/50 [==============================] - 527s 11s/step - loss: 2.7230 - accuracy: 0.3150\n",
            "Epoch 11/25\n",
            "50/50 [==============================] - 525s 10s/step - loss: 2.5161 - accuracy: 0.3658\n",
            "Epoch 12/25\n",
            "50/50 [==============================] - 525s 10s/step - loss: 2.2176 - accuracy: 0.4363\n",
            "Epoch 13/25\n",
            "50/50 [==============================] - 525s 10s/step - loss: 1.9648 - accuracy: 0.4947\n",
            "Epoch 14/25\n",
            "50/50 [==============================] - 523s 10s/step - loss: 1.6799 - accuracy: 0.5699\n",
            "Epoch 15/25\n",
            "50/50 [==============================] - 523s 10s/step - loss: 1.4260 - accuracy: 0.6272\n",
            "Epoch 16/25\n",
            "50/50 [==============================] - 523s 10s/step - loss: 1.1827 - accuracy: 0.6924\n",
            "Epoch 17/25\n",
            "50/50 [==============================] - 524s 10s/step - loss: 1.0164 - accuracy: 0.7348\n",
            "Epoch 18/25\n",
            "50/50 [==============================] - 533s 11s/step - loss: 0.8097 - accuracy: 0.7862\n",
            "Epoch 19/25\n",
            "50/50 [==============================] - 523s 10s/step - loss: 0.6340 - accuracy: 0.8277\n",
            "Epoch 20/25\n",
            "50/50 [==============================] - 523s 10s/step - loss: 0.5442 - accuracy: 0.8564\n",
            "Epoch 21/25\n",
            "50/50 [==============================] - 522s 10s/step - loss: 0.4578 - accuracy: 0.8753\n",
            "Epoch 22/25\n",
            "50/50 [==============================] - 525s 10s/step - loss: 0.3528 - accuracy: 0.9053\n",
            "Epoch 23/25\n",
            "50/50 [==============================] - 527s 11s/step - loss: 0.3208 - accuracy: 0.9119\n",
            "Epoch 24/25\n",
            "50/50 [==============================] - 525s 10s/step - loss: 0.2668 - accuracy: 0.9264\n",
            "Epoch 25/25\n",
            "50/50 [==============================] - 526s 10s/step - loss: 0.2331 - accuracy: 0.9317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR4Yfq0GUfgL"
      },
      "source": [
        "model.save('food_image_selector.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLr2u3kvUfgL",
        "outputId": "b3f8ac1d-7ce1-4340-e61a-829e4a2becc4"
      },
      "source": [
        "model.save('food_image_selector.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: food_image_selector.json/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHhkrcfHUfgM"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SzaMBkrUfgN"
      },
      "source": [
        "???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-1jEoC-UfgN",
        "outputId": "20f99720-7c38-4c9e-c92b-15e15688262e"
      },
      "source": [
        "# 사진 입력시 출력 내용\n",
        "# 파일명 및 경로 설정 필요\n",
        "\n",
        "# file = path + '\\\\' + menu[1] + '\\\\' + menu_img_file_name[1][0]\n",
        "file_name = 'Img_000_0000.jpg'\n",
        "\n",
        "#path -> 입력 사진으로 변경\n",
        "img = image.load_img(file, target_size=(300, 300))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "\n",
        "for i in range(len(classes[0])):\n",
        "    if classes[0][i] == 1:\n",
        "        print(file_name, '은/는 ', menu[i], ' 입니다.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Img_000_0000.jpg 은/는  갈비탕  입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDfrxKHlUfgP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}